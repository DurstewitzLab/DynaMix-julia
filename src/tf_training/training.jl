using Flux
using BSON: @save
using DataStructures
using JLD
using Statistics
using NaNStatistics

using ..ReconstructionMeasures
using ..Model
using ..ObservationModels
using ..Utilities

"""
    loss(tfrec, XÌƒ, CÌƒ)

Performs a forward pass using the teacher forced recursion wrapper `tfrec` and
computes and return the loss w.r.t. data `XÌƒ`. Optionally external context `CÌƒ`
can be provided.
"""

function loss(
    tfrec::AbstractTFRecur,
    XÌƒ::AbstractArray{T, 3},
    áº::AbstractArray{T, 3},
    CÌƒ::AbstractArray{T, 2},  # 2D array: context_size Ã— batch_size
) where {T}
    Z = tfrec(XÌƒ, áº, CÌƒ)
    XÌ‚ = tfrec.O(Z)
    return @views Flux.mse(XÌ‚, XÌƒ[:, :, 2:end])
end

"""
    regularization_loss(tfrec, Î»â‚—, Î»â‚’)

Computes the regularization loss for the model `tfrec` with latent model regularization parameter `Î»â‚—`
and observation model regularization parameter `Î»â‚’`.
"""
function regularization_loss(
    tfrec::AbstractTFRecur,
    Î»â‚—::Float32,
    Î»â‚’::Float32,
)
    # latent model regularization
    Láµ£ = 0.0f0

    if Î»â‚— > 0
        Láµ£ += regularize(tfrec.model, Î»â‚—)
    end

    # observation model regularization
    Láµ£ += (Î»â‚’ > 0) ? regularize(tfrec.O, Î»â‚’) : 0
    return Láµ£
end

function regularize(m::AbstractDynaMix, Î»::Float32; c = 0.01)
    return Î» * mean(exp.(-abs.(m.gating_network.sigma) ./ c))
end


"""
    train_!(m, O, ð’Ÿ, opt, args, save_path)

Train a model `m` with observation model `O` on dataset `ð’Ÿ` using the optimizer `opt`.
"""

function train_!(
    m::AbstractDynaMix,
    O::ObservationModel,
    ð’Ÿ::AbstractDataset,
    opt::Flux.Optimise.Optimiser,
    args::AbstractDict,
    save_path::String,
)
    # hypers
    E = args["epochs"]::Int
    M = args["latent_dim"]::Int
    Sâ‚‘ = args["batches_per_epoch"]::Int
    S = args["batch_size"]::Int
    Ï„ = args["teacher_forcing_interval"]::Int
    Ïƒ_noise = args["gaussian_noise_level"]::Float32
    TÌƒ = args["sequence_length"]::Int
    ÏƒÂ²_scaling = args["D_stsp_scaling"]::Float32
    bins = args["D_stsp_bins"]::Int
    Ïƒ_smoothing = args["PSE_smoothing"]::Float32
    PE_n = args["PE_n"]::Int
    isi = args["image_saving_interval"]::Int
    ssi = args["scalar_saving_interval"]::Int
    exp = args["experiment"]::String
    name = args["name"]::String
    run = args["run"]::Int
    Î± = args["gtf_alpha"]::Float32
    Î±_method = args["gtf_alpha_method"]::String
    Î³ = args["gtf_alpha_decay"]::Float32
    Î»â‚’ = args["obs_model_regularization"]::Float32
    Î»â‚— = args["lat_model_regularization"]::Float32
    partial_forcing = args["partial_forcing"]::Bool
    k = args["alpha_update_interval"]::Int
    use_gtf = args["use_gtf"]::Bool

    # data shape
    T, N, n = size(ð’Ÿ.X)

    #metrics
    metrics = []

    # zero-shot testing hyperparameters
    if ð’Ÿ.Test_data !== nothing
        test_context_length = 2000
        test_prediction_length = size(ð’Ÿ.Test_data,1) - test_context_length
        test_systems = size(ð’Ÿ.Test_data,3)
    end

    # progress tracking
    prog = Progress(joinpath(exp, name), run, 20, E, 0.8)

    # decide on D_stsp scaling
    scal, stsp_name = decide_on_measure(ÏƒÂ²_scaling, bins, size(ð’Ÿ.Test_data,2))

    # initialize stateful model wrapper
    zâ‚€ = similar(ð’Ÿ.X, M, S)
    if use_gtf
        tfrec = GTFRecur(m, O, zâ‚€, Î±)
        println(
            "Using GTF with initial Î± = $Î± and annealing method: $Î±_method (Î³ = $Î³, k = $k)",
        )
        println("Partial forcing set to: $partial_forcing (N = $N, M = $M)")
    else
        tfrec = TFRecur(m, O, zâ‚€, Ï„)
        println("Using sparse TF with Ï„ = $Ï„")
        println("Partial forcing set to: $partial_forcing (N = $N, M = $M)")
    end

    # model parameters
    Î¸ = Flux.params(tfrec)

    # initial Î±
    Î±_est = Î±

    # losses
    âˆ‘L, Lâ‚œáµ£, Láµ£ = 0.0f0, 0.0f0, 0.0f0

    for e = 1:E
        # process a couple of batches
        tâ‚ = time_ns()
        for sâ‚‘ = 1:Sâ‚‘
            # sample a batch
            XÌƒ, CÌƒ_exts = sample_batch(ð’Ÿ, TÌƒ, S)
            CÌƒ_exts = (CÌƒ_exts,)

            # add noise noise if noise level > 0
            Ïƒ_noise > zero(Ïƒ_noise) ? add_gaussian_noise!(XÌƒ, Ïƒ_noise) : nothing

            # precompute forcing signals
            áº = estimate_forcing_signals(tfrec, XÌƒ)

            # Î± estimation & annealing
            if sâ‚‘ % k == 0 && use_gtf
                Î±_est = compute_Î±(tfrec, @view(áº[:, :, 2:end]), Î±_method)
                if Î±_est > tfrec.Î±
                    tfrec.Î± = Î±_est
                else
                    tfrec.Î± = Î³ * tfrec.Î± + (1 - Î³) * Î±_est
                end
            end

            # partial forcing
            @views áº_subset = partial_forcing ? áº[1:N, :, 2:end] : áº[:, :, 2:end]

            # forward and backward pass
            (âˆ‘L, Lâ‚œáµ£, Láµ£), grads = Flux.withgradient(Î¸) do
                Lâ‚œáµ£ = loss(tfrec, XÌƒ, áº_subset, CÌƒ_exts...)
                Láµ£ = regularization_loss(tfrec, Î»â‚—, Î»â‚’)
                return Lâ‚œáµ£ + Láµ£, Lâ‚œáµ£, Láµ£
            end

            # optimiser step
            Flux.Optimise.update!(opt, Î¸, grads)

            # check for NaNs in parameters (exploding gradients)
            if check_for_NaNs(Î¸)
                save_model(
                    [tfrec.model, tfrec.O],
                    joinpath(save_path, "checkpoints", "model_$e.bson"),
                )
                save(joinpath("Results", args["experiment"], args["name"], Utilities.format_run_ID(args["run"]), "metrics.jld"), "metrics", metrics)
                @warn "NaN(s) in parameters detected! \
                    This is likely due to exploding gradients. Aborting training..."
                return nothing
            end
        end
        tâ‚‚ = time_ns()
        Î”t = (tâ‚‚ - tâ‚) / 1e9
        update!(prog, Î”t, e)

        # Monitoring metrics
        if e % ssi == 0

            # Calculate zero-shot metrics if test data is provided
            if ð’Ÿ.Test_data !== nothing
                D_stsp_all = []; D_H_all = []; pe_all = []
                for i in 1:test_systems
                    X_gen = DynaMix_forecasting_pipeline(tfrec.model, tfrec.O, ð’Ÿ.Test_data[1:test_context_length, :, i], 
                            test_prediction_length, preprocessing_method="zero_embedding",standardize=true)
                    
                    push!(D_stsp_all, state_space_divergence(Float32.(ð’Ÿ.Test_data[test_context_length+1:end, :, i]), Float32.(X_gen), scal)) # gets calculated separately for each trajectory
                    push!(D_H_all, power_spectrum_error(Float32.(ð’Ÿ.Test_data[test_context_length+1:end, :, i]), Float32.(X_gen), Ïƒ_smoothing)) # same here
                    push!(pe_all, MASE(Float32.(ð’Ÿ.Test_data[test_context_length+1:end, :, i]), Float32.(X_gen),PE_n))
                end
                D_stsp = nanmedian(Float32.(D_stsp_all)); D_H = nanmedian(Float32.(D_H_all)); pe = nanmedian(Float32.(pe_all))
            else
                D_stsp = 0; D_H = 0; pe = 0
            end

            # progress printing
            scalars = OrderedDict("âˆ‘L" => âˆ‘L)
            Láµ£ > 0.0f0 ? scalars["Lâ‚œáµ£"] = Lâ‚œáµ£ : nothing
            Láµ£ > 0.0f0 ? scalars["Láµ£"] = Láµ£ : nothing
            scalars["Dâ‚›â‚œâ‚›â‚š $stsp_name"] = D_stsp
            scalars["Dâ‚•"] = D_H
            scalars["PE($PE_n)"] = pe
            typeof(tfrec) <: GTFRecur ? scalars["Î±"] = round(tfrec.Î±, digits = 3) : nothing
            push!(metrics, getindex.(Ref(scalars), ["âˆ‘L","Dâ‚›â‚œâ‚›â‚š $stsp_name", "Dâ‚•","PE($PE_n)"]))

            print_progress(prog, Î”t, scalars)

            # Save model
            save_model(
                [tfrec.model, tfrec.O],
                joinpath(save_path, "checkpoints", "model_$e.bson"),
            )

            # Plot trajectory if test data is provided
            if e % isi == 0 && ð’Ÿ.Test_data !== nothing
                @views plot_reconstruction(
                    Float32.(DynaMix_forecasting_pipeline(tfrec.model, tfrec.O, 
                        ð’Ÿ.Test_data[1:test_context_length, :, 1], test_prediction_length,
                        preprocessing_method="zero_embedding",standardize=true)),
                    Float32.(ð’Ÿ.Test_data[test_context_length+1:end, :, 1]),
                    joinpath(save_path, "plots", "generated_$e.png"),
                )
            end
        end
    end

    #Save training metrics
    save(joinpath("Results", args["experiment"], args["name"], Utilities.format_run_ID(args["run"]), "metrics.jld"), "metrics", metrics)

    return nothing
end
